{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agente LLM Personalizado (con un modelo de Chat y Memoria)\n",
    "---\n",
    "\n",
    "Este cuaderno explica cómo crear su propio agente personalizado basado en un modelo de chat. \n",
    "\n",
    "Un agente de chat LLM consta de tres partes:\n",
    "\n",
    "- `PromptTemplate`: Esta es la plantilla de indicaciones que se puede utilizar para indicarle al modelo de lenguaje qué hacer\n",
    "- `ChatModel`: Este es el modelo de lenguaje que impulsa al agente.\n",
    "- `stop sequence`: Le indica al LLM que deje de generar tan pronto como se encuentre esta cadena\n",
    "- `OutputParser`: Esto determina cómo analizar la salida de `LLM` en un objeto `AgentAction` o `AgentFinish`.\n",
    "\n",
    "El Agente `LLM` se utiliza en un `AgentExecutor`. Este `AgentExecutor` puede considerarse en gran medida como un bucle que:\n",
    "\n",
    "1. Pasa la entrada del usuario y cualquier paso previo al Agente (en este caso, el Agente LLM)\n",
    "2. Si el Agente devuelve un `AgentFinish`, devuélvalo directamente al usuario.\n",
    "3. Si el Agente devuelve una `AgentAction`, úsela para llamar a una herramienta (`tool`) y obtener una Observación (`Observation`)\n",
    "4. Repita, pasando `AgentAction` y `Observation` nuevamente al Agente hasta que se emita un `AgentFinish`.\n",
    "\n",
    "`AgentAction` es una respuesta que consta de `action` y `action_input`. \n",
    "\n",
    "- `action` se refiere a qué herramienta usar \n",
    "- `action_input` se refiere a la entrada a esa herramienta. \n",
    "- `log` también se puede proporcionar como más contexto (que se puede usar para registrar, rastrear, etc.).\n",
    "\n",
    "`AgentFinish` es una respuesta que contiene el mensaje final que se enviará al usuario. Esto debe usarse para finalizar la ejecución de un agente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuracion del Entorno\n",
    "---\n",
    "\n",
    "Realizar las importaciones necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "from typing import List, Union\n",
    "import re\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar herramienta (tools)\n",
    "---\n",
    "\n",
    "Configure cualquier herramienta (`tool`) que el agente quiera utilizar. \n",
    "\n",
    "Puede ser necesario incluir esto en el `prompt` (para que el agente sepa cómo utilizar estas herramientas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plantilla de Prompt (Prompt Template)\n",
    "---\n",
    "\n",
    "Esto le indica al agente qué hacer. Generalmente, la plantilla debe incorporar:\n",
    "\n",
    "- `tools`: a qué herramientas tiene acceso el agente y cómo y cuándo llamarlas.\n",
    "- `intermediate_steps`: Estas son tuplas de pares anteriores (`AgentAction`, `Observation`). Por lo general, estos no se pasan directamente al modelo, pero el `prompt template` les da formato de una manera específica.\n",
    "- `input`: entrada genérica del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"Complete the objective as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "These were previous tasks you completed:\n",
    "\n",
    "\n",
    "\n",
    "Begin!\n",
    "\n",
    "Previous conversation history:\n",
    "{chat_history}\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        \n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"chat_history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizador de salida (Output parser)\n",
    "---\n",
    "\n",
    "El analizador de salida (output parser) es responsable de analizar la salida de LLM en `AgentAction` y `AgentFinish`. Por lo general, esto depende en gran medida del mensaje utilizado.\n",
    "\n",
    "Aquí es donde puede cambiar el análisis para realizar reintentos, manejar espacios en blanco, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar el LLM\n",
    "---\n",
    "\n",
    "¡Elija el LLM que desea utilizar!\n",
    "\n",
    "Para este ejemplo usaremos ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir la secuencia de parada (stop sequence)\n",
    "---\n",
    "\n",
    "Esto es importante porque le indica al `LLM` cuándo detener la generación.\n",
    "\n",
    "Esto depende en gran medida del indicador y del modelo que esté utilizando. Generalmente, desea que sea cualquier token que use en el mensaje para indicar el inicio de una observación (de lo contrario, el LLM puede alucinar una observación para usted)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar el Agente\n",
    "---\n",
    "\n",
    "Ahora podemos combinar todo para configurar nuestro agente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilice el agente\n",
    "---\n",
    "\n",
    "¡Ahora podemos usarlo!\n",
    "\n",
    "Comencemos por crear el \"ejecutor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hagamos una pregunta a nuestro agente, por ejemplo preguntemos ¿cuantas persoas viven en canada en el año 2023?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I don't have the current population data for Canada in 2023.\n",
      "Action: Search\n",
      "Action Input: \"current population of Canada 2023\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m38,781,291 people\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the current population of Canada in 2023.\n",
      "Final Answer: The current population of Canada as of 2023 is 38,781,291 people.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current population of Canada as of 2023 is 38,781,291 people.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"How many people live in Canada as of 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the current population of Mexico.\n",
      "Action: Search\n",
      "Action Input: \"current population of Mexico\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m{'type': 'population_result', 'place': 'Mexico', 'population': '126.7 million', 'year': '2021'}\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe current population of Mexico is 126.7 million as of 2021.\n",
      "Final Answer: The current population of Mexico is 126.7 million.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current population of Mexico is 126.7 million.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"how about in mexico?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar el agente al no tener \"estado\", no comprende la pregunta en la conversacion.\n",
    "\n",
    "Tendriamos que hacer la pregunta directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the current population of Colombia.\n",
      "Action: Search\n",
      "Action Input: \"current population of Colombia\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m{'type': 'population_result', 'place': 'Colombia', 'population': '51.52 million', 'year': '2021'}\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe current population of Colombia is 51.52 million as of 2021.\n",
      "Final Answer: The current population of Colombia is 51.52 million.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current population of Colombia is 51.52 million.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"how about colombia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out the name of the national anthem for Canada, Mexico, and Colombia.\n",
      "Action: Search\n",
      "Action Input: \"national anthem of Canada\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m['\"O Canada\" is the national anthem of Canada. The song was originally commissioned by Lieutenant Governor of Quebec Théodore Robitaille for the 1880 Saint-Jean-Baptiste Day ceremony; Calixa Lavallée composed the music, after which words were written by the poet and judge Sir Adolphe-Basile Routhier.', 'O Canada type: National anthem.', 'O Canada main_tab_text: Overview.', 'O Canada kgmid: /m/05mtn.', 'O Canada lyricists: Calixa Lavallée, Robert Stanley Weir, Adolphe-Basile Routhier.', 'O Canada composer: Calixa Lavallée.', 'O Canada key: G major.', 'O Canada adopted: July 1, 1980.', 'O Canada also_known_as: French - Ô Canada.', 'It was proclaimed the official national anthem on July 1, 1980. “God Save the Queen” remains the royal anthem of Canada. The music, written by ...']\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to search for the national anthems of Mexico and Colombia as well.\n",
      "Action: Search\n",
      "Action Input: \"national anthem of Mexico\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m['The \"Mexican National Anthem\", also known by its incipit \"Mexicans, at the cry of war\", is the national anthem of Mexico. The anthem was first used in 1854.', 'Himno Nacional Mexicano type: National anthem.', 'Himno Nacional Mexicano main_tab_text: Overview.', 'Himno Nacional Mexicano kgmid: /m/012144.', 'Himno Nacional Mexicano lyricist: Francisco González Bocanegra.', 'Himno Nacional Mexicano composed: 1854.', 'Himno Nacional Mexicano key: C major.', 'Himno Nacional Mexicano composer: Jaime Nunó.', 'Himno Nacional Mexicano lyrics: Francisco González Bocanegra, 1853.', 'Himno Nacional Mexicano adopted: 4 May 1943.', 'The \"Mexican National Anthem\" (Spanish: Himno Nacional Mexicano, pronounced [\\'imno nasjo\\'nal mexi\\'kano]; Nahuatl languages: Mexihcaletepetlacuicalt), ...']\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI still need to search for the national anthem of Colombia.\n",
      "Action: Search\n",
      "Action Input: \"national anthem of Colombia\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m['The \"National Anthem of the Republic of Colombia\" is the official name of the national anthem of Colombia. It was originally written as a poem in 1850 by future President Rafael Núñez as an ode to celebrate the independence of Cartagena.', 'National Anthem of Colombia main_tab_text: Overview.', 'National Anthem of Colombia kgmid: /m/01prgy.', 'National Anthem of Colombia lyricist: Rafael Núñez.', 'National Anthem of Colombia composer: Oreste Sindici.', 'National Anthem of Colombia key: E-flat major.', 'National Anthem of Colombia lyrics: Rafael Núñez, 1850, 1883.', 'National Anthem of Colombia adopted: 28 October 1920.', 'National Anthem of Colombia music: Oreste Sindici, 1887.', 'The \"National Anthem of the Republic of Colombia\" (Spanish: Himno Nacional de la República de Colombia, pronounced [ˌimno nasjoˈnal de la reˌpuβlika ðe ...']\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The national anthem of Canada is called \"O Canada\", the national anthem of Mexico is called \"Mexican National Anthem\", and the national anthem of Colombia is called \"National Anthem of the Republic of Colombia\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The national anthem of Canada is called \"O Canada\", the national anthem of Mexico is called \"Mexican National Anthem\", and the national anthem of Colombia is called \"National Anthem of the Republic of Colombia\".'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"what is their national anthem called?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Holochat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
